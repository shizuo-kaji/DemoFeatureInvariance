{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "intro-markdown"
   },
   "source": [
    "# Invariance and Representation in Machine Learning\n",
    "\n",
    "This notebook demonstrates how **input representation** (feature engineering) critically impacts machine learning performance. You will explore this concept using a simple, interpretable geometric dataset: 2D triangles.\n",
    "\n",
    "## Learning Objectives\n",
    "1.  **Feature Representation**: Why raw data (e.g., coordinates) isn't always the best input.\n",
    "2.  **Invariance**: How removing \"nuisance\" variations (rotation, translation) simplifies learning.\n",
    "3.  **Target Dependence**: A representation good for *area* might be bad for *position*.\n",
    "\n",
    "## The Task\n",
    "Predict three targets from triangle coordinates $(x_1, y_1), (x_2, y_2), (x_3, y_3)$:\n",
    "1.  **$u$ (Position)**: Centroid sum ($x_c + y_c$). Depends on absolute position.\n",
    "2.  **$v$ (Area)**: Triangle area. Depends on shape & scale.\n",
    "3.  **$w$ (Shape)**: Sum of squared angles. Depends only on intrinsic shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-cell"
   },
   "outputs": [],
   "source": [
    "# @title 1. Setup & Dependencies\n",
    "# Run this cell to install necessary packages and import libraries.\n",
    "\n",
    "!pip install -q numpy pandas scikit-learn matplotlib seaborn\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "np.random.seed(42)\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-generation"
   },
   "outputs": [],
   "source": [
    "# @title 2. Data Generation\n",
    "# This function generates random triangles and calculates u, v, w.\n",
    "\n",
    "def area_triangle(x1, y1, x2, y2, x3, y3):\n",
    "    return 0.5 * abs(x1*(y2-y3) + x2*(y3-y1) + x3*(y1-y2))\n",
    "\n",
    "def centroid_sum(x1, y1, x2, y2, x3, y3):\n",
    "    return (x1 + x2 + x3)/3.0 + (y1 + y2 + y3)/3.0\n",
    "\n",
    "def get_angles(x1, y1, x2, y2, x3, y3):\n",
    "    a = np.hypot(x2-x3, y2-y3)\n",
    "    b = np.hypot(x1-x3, y1-y3)\n",
    "    c = np.hypot(x1-x2, y1-y2)\n",
    "    if a==0 or b==0 or c==0: return float('nan')\n",
    "    # Law of cosines\n",
    "    def safe_acos(val):\n",
    "        return math.acos(max(-1.0, min(1.0, val)))\n",
    "    A = safe_acos((b**2 + c**2 - a**2)/(2*b*c))\n",
    "    B = safe_acos((a**2 + c**2 - b**2)/(2*a*c))\n",
    "    C = safe_acos((a**2 + b**2 - c**2)/(2*a*b))\n",
    "    return A, B, C\n",
    "\n",
    "def generate_dataset(n=2000):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        # Generate random coordinates in [-10, 10]\n",
    "        coords = np.random.uniform(-10, 10, 6)\n",
    "        x1, y1, x2, y2, x3, y3 = coords\n",
    "\n",
    "        v = area_triangle(x1, y1, x2, y2, x3, y3)\n",
    "        if v < 1e-3: continue # Skip degenerate triangles\n",
    "\n",
    "        u = centroid_sum(x1, y1, x2, y2, x3, y3)\n",
    "        angles = get_angles(x1, y1, x2, y2, x3, y3)\n",
    "        if isinstance(angles, float): continue\n",
    "        w = sum([ang**2 for ang in angles])\n",
    "\n",
    "        row = {'x1':x1, 'y1':y1, 'x2':x2, 'y2':y2, 'x3':x3, 'y3':y3, 'u':u, 'v':v, 'w':w}\n",
    "        data.append(row)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = generate_dataset()\n",
    "print(f\"Generated {len(df)} samples.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "helper-functions"
   },
   "outputs": [],
   "source": [
    "# @title 3. Helper Functions: Training & Preprocessing\n",
    "\n",
    "REGRESSORS = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'MLP (Neural Net)': MLPRegressor(hidden_layer_sizes=(64,32), max_iter=1000, random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "}\n",
    "\n",
    "def preprocess_data(df, mode='none'):\n",
    "    # Extract raw coords\n",
    "    X_raw = df[['x1','y1','x2','y2','x3','y3']].values\n",
    "\n",
    "    if mode == 'none':\n",
    "        return pd.DataFrame(X_raw, columns=['x1','y1','x2','y2','x3','y3'])\n",
    "\n",
    "    elif mode == 'congruent':\n",
    "        # Translate p1 to origin, rotate p2 to x-axis\n",
    "        new_X = []\n",
    "        for row in X_raw:\n",
    "            x1,y1,x2,y2,x3,y3 = row\n",
    "            # Translate\n",
    "            tx2, ty2 = x2-x1, y2-y1\n",
    "            tx3, ty3 = x3-x1, y3-y1\n",
    "            # Rotate\n",
    "            theta = math.atan2(ty2, tx2)\n",
    "            c, s = math.cos(-theta), math.sin(-theta)\n",
    "            rx2 = tx2*c - ty2*s\n",
    "            ry2 = tx2*s + ty2*c # Should be 0\n",
    "            rx3 = tx3*c - ty3*s\n",
    "            ry3 = tx3*s + ty3*c\n",
    "            # Flip if y3 < 0 to handle reflection\n",
    "            if ry3 < 0: ry3 = -ry3\n",
    "            new_X.append([rx2, rx3, ry3])\n",
    "        return pd.DataFrame(new_X, columns=['x2_new','x3_new','y3_new'])\n",
    "\n",
    "    elif mode == 'similar':\n",
    "        # Same as congruent but scale so p2 is at (1,0)\n",
    "        new_X = []\n",
    "        for row in X_raw:\n",
    "            x1,y1,x2,y2,x3,y3 = row\n",
    "            # Translate\n",
    "            tx2, ty2 = x2-x1, y2-y1\n",
    "            tx3, ty3 = x3-x1, y3-y1\n",
    "            # Rotate\n",
    "            dist_p1p2 = math.hypot(tx2, ty2)\n",
    "            theta = math.atan2(ty2, tx2)\n",
    "            scale = 1.0 / dist_p1p2 if dist_p1p2 != 0 else 0\n",
    "            c, s = math.cos(-theta), math.sin(-theta)\n",
    "            # Apply rotation & scale to p3\n",
    "            rx3 = (tx3*c - ty3*s) * scale\n",
    "            ry3 = (tx3*s + ty3*c) * scale\n",
    "            if ry3 < 0: ry3 = -ry3\n",
    "            new_X.append([rx3, ry3])\n",
    "        return pd.DataFrame(new_X, columns=['x3_sim','y3_sim'])\n",
    "\n",
    "    elif mode == 'length':\n",
    "        # Edge lengths\n",
    "        new_X = []\n",
    "        for row in X_raw:\n",
    "            x1,y1,x2,y2,x3,y3 = row\n",
    "            a = math.hypot(x2-x3, y2-y3)\n",
    "            b = math.hypot(x1-x3, y1-y3)\n",
    "            c = math.hypot(x1-x2, y1-y2)\n",
    "            new_X.append([a,b,c])\n",
    "        return pd.DataFrame(new_X, columns=['len_a','len_b','len_c'])\n",
    "\n",
    "    elif mode == 'angle':\n",
    "        # Two angles\n",
    "        new_X = []\n",
    "        for row in X_raw:\n",
    "            x1,y1,x2,y2,x3,y3 = row\n",
    "            A, B, C = get_angles(x1,y1,x2,y2,x3,y3)\n",
    "            new_X.append([A, B])\n",
    "        return pd.DataFrame(new_X, columns=['angle_A','angle_B'])\n",
    "\n",
    "def run_experiment(df, mode='none'):\n",
    "    X = preprocess_data(df, mode)\n",
    "    y = df[['u', 'v', 'w']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    results = []\n",
    "    print(f\"--- Results for Mode: {mode} ---\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    print(f\"{'Target':<10} | {'Model':<15} | {'R2 Score':<10} | {'MSE':<10}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "\n",
    "    for target in ['u', 'v', 'w']:\n",
    "        for name, model in REGRESSORS.items():\n",
    "            pipe = make_pipeline(StandardScaler(), model)\n",
    "            pipe.fit(X_train, y_train[target])\n",
    "            pred = pipe.predict(X_test)\n",
    "            r2 = r2_score(y_test[target], pred)\n",
    "            mse = mean_squared_error(y_test[target], pred)\n",
    "            results.append({'mode': mode, 'target': target, 'model': name, 'r2': r2, 'mse': mse})\n",
    "\n",
    "            if r2 > 0.5: color = '\\033[92m' # Green for good\n",
    "            elif r2 > 0: color = '\\033[93m' # Yellow for okay\n",
    "            else: color = '\\033[91m'       # Red for bad\n",
    "\n",
    "            print(f\"{target:<10} | {name:<15} | {color}{r2:.4f}\\033[0m     | {mse:.4f}\")\n",
    "        print(f\"{'-'*60}\")\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exp1-intro"
   },
   "source": [
    "## Experiment 1: Raw Coordinates (`none`)\n",
    "**Hypothesis:**\n",
    "- $u$ (Position): Should be easy (Linear). $u$ is literally a linear combination of inputs.\n",
    "- $v$ (Area): Should be harder. Area is non-linear (multiplicative).\n",
    "- $w$ (Angles): Should be hard. Angles involve trigonometry (highly non-linear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exp1-run"
   },
   "outputs": [],
   "source": [
    "res_none = run_experiment(df, mode='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exp2-intro"
   },
   "source": [
    "## Experiment 2: Invariance (`congruent`)\n",
    "We translate the triangle so $p_1$ is at $(0,0)$ and rotate it so $p_2$ is on the x-axis.\n",
    "\n",
    "**Hypothesis:**\n",
    "- **Position information is destroyed.** $u$ prediction should fail.\n",
    "- **Area and Shape information is preserved.** $v$ and $w$ should improve because the model doesn't have to learn rotation invariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exp2-run"
   },
   "outputs": [],
   "source": [
    "res_congruent = run_experiment(df, mode='congruent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exp3-intro"
   },
   "source": [
    "## Experiment 3: Scale Invariance (`similar`)\n",
    "We translate, rotate, AND scale the triangle so the base length is 1.\n",
    "\n",
    "**Hypothesis:**\n",
    "- **Scale information is destroyed.** Area $v$ depends on scale, so prediction should fail.\n",
    "- **Shape information is preserved.** Angles $w$ only depend on shape, so they should still be predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exp3-run"
   },
   "outputs": [],
   "source": [
    "res_similar = run_experiment(df, mode='similar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exp4-intro"
   },
   "source": [
    "## Experiment 4: Explicit Features (`length`)\n",
    "We replace coordinates with the three edge lengths $(a, b, c)$.\n",
    "\n",
    "**Hypothesis:**\n",
    "- Similar to `congruent`, but explicitly provides the geometry the area formula needs (Heron's formula).\n",
    "- $v$ (Area) prediction should be very strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exp4-run"
   },
   "outputs": [],
   "source": [
    "res_length = run_experiment(df, mode='length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-intro"
   },
   "source": [
    "## Summary & Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary-plot"
   },
   "outputs": [],
   "source": [
    "all_results = pd.concat([res_none, res_congruent, res_similar, res_length])\n",
    "\n",
    "# Filter for best model per mode/target (max R2)\n",
    "best_results = all_results.loc[all_results.groupby(['mode', 'target'])['r2'].idxmax()]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=best_results, x='target', y='r2', hue='mode')\n",
    "plt.title(\"Best R2 Score per Target by Representation\")\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.axhline(0, color='black', linewidth=1)\n",
    "plt.ylabel(\"R2 Score (Higher is better)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
